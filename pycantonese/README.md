# Temporary project for training model in Python

## Building tokenizer

For building a tokenizer, it is needed to use `sentencepiece` binary right now

```sh
brew install sentencepiece
```